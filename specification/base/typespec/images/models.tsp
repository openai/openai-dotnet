/*
 * This file was automatically generated from an OpenAPI .yaml file.
 * Edits made directly to this file will be lost.
 */

import "./custom.tsp";

using Http;
using TypeSpec.OpenAPI;

namespace OpenAI;

model CreateImageRequest {
  @doc("""
    A text description of the desired image(s). The maximum length is 32000 characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.
    """)
  prompt: string;

  @doc("""
    The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.
    """)
  @extension("x-oaiTypeLabel", "string")
  `model`?:
    | string
    | "dall-e-2"
    | "dall-e-3"
    | "gpt-image-1"
    | null = "dall-e-2";

  @doc("""
    The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.
    """)
  @minValue(1)
  @maxValue(10)
  n?: int32 | null = 1;

  @doc("""
    The quality of the image that will be generated.
    
    - `auto` (default value) will automatically select the best quality for the given model.
    - `high`, `medium` and `low` are supported for `gpt-image-1`.
    - `hd` and `standard` are supported for `dall-e-3`.
    - `standard` is the only option for `dall-e-2`.
    """)
  quality?:
    | "standard"
    | "hd"
    | "low"
    | "medium"
    | "high"
    | "auto"
    | null = "auto";

  @doc("""
    The format in which generated images with `dall-e-2` and `dall-e-3` are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter isn't supported for `gpt-image-1` which will always return base64-encoded images.
    """)
  response_format?: "url" | "b64_json" | null = "url";

  @doc("""
    The format in which the generated images are returned. This parameter is only supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.
    """)
  output_format?: "png" | "jpeg" | "webp" | null = "png";

  @doc("""
    The compression level (0-100%) for the generated images. This parameter is only supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and defaults to 100.
    """)
  output_compression?: int32 | null = 100;

  @doc("""
    The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.
    """)
  size?:
    | "auto"
    | "1024x1024"
    | "1536x1024"
    | "1024x1536"
    | "256x256"
    | "512x512"
    | "1792x1024"
    | "1024x1792"
    | null = "auto";

  @doc("""
    Control the content-moderation level for images generated by `gpt-image-1`. Must be either `low` for less restrictive filtering or `auto` (default value).
    """)
  moderation?: "low" | "auto" | null = "auto";

  @doc("""
    Allows to set transparency for the background of the generated image(s).
    This parameter is only supported for `gpt-image-1`. Must be one of
    `transparent`, `opaque` or `auto` (default value). When `auto` is used, the
    model will automatically determine the best background for the image.
    
    If `transparent`, the output format needs to support transparency, so it
    should be set to either `png` (default value) or `webp`.
    """)
  background?: "transparent" | "opaque" | "auto" | null = "auto";

  @doc("""
    The style of the generated images. This parameter is only supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images.
    """)
  style?: "vivid" | "natural" | null = "vivid";

  /** A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids). */
  user?: string;
}

model CreateImageEditRequest {
  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    The image(s) to edit. Must be a supported image file or an array of images.
    
    For `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less
    than 50MB. You can provide up to 16 images.
    
    For `dall-e-2`, you can only provide one image, and it should be a square
    `png` file less than 4MB.
    """)
  image: HttpPart<bytes | bytes[]>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`.
    """)
  prompt: HttpPart<string>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. If there are multiple images provided, the mask will be applied on the first image. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.
    """)
  mask?: HttpPart<bytes>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    Allows to set transparency for the background of the generated image(s).
    This parameter is only supported for `gpt-image-1`. Must be one of
    `transparent`, `opaque` or `auto` (default value). When `auto` is used, the
    model will automatically determine the best background for the image.
    
    If `transparent`, the output format needs to support transparency, so it
    should be set to either `png` (default value) or `webp`.
    """)
  background?: HttpPart<"transparent" | "opaque" | "auto" | null>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    The model to use for image generation. Only `dall-e-2` and `gpt-image-1` are supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.
    """)
  @extension("x-oaiTypeLabel", "string")
  `model`?: HttpPart<string | "dall-e-2" | "gpt-image-1" | null>;

  // Tool customization: Use scenario-specific composed union and apply HttpPart for property in multipart request model
  /** The number of images to generate. Must be between 1 and 10. */
  n?: HttpPart<OneToTenInt | null>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.
    """)
  size?: HttpPart<
    | "256x256"
    | "512x512"
    | "1024x1024"
    | "1536x1024"
    | "1024x1536"
    | "auto"
    | null>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for `dall-e-2`, as `gpt-image-1` will always return base64-encoded images.
    """)
  response_format?: HttpPart<"url" | "b64_json" | null>;

  // Tool customization: Apply HttpPart for property in multipart request model
  /** A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids). */
  user?: HttpPart<string>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`.
    """)
  quality?: HttpPart<"standard" | "low" | "medium" | "high" | "auto" | null>;
}

model CreateImageVariationRequest {
  // Tool customization: Apply HttpPart for property in multipart request model
  /** The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square. */
  image: HttpPart<bytes>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    The model to use for image generation. Only `dall-e-2` is supported at this time.
    """)
  @extension("x-oaiTypeLabel", "string")
  `model`?: HttpPart<string | "dall-e-2" | null>;

  // Tool customization: Use scenario-specific composed union and apply HttpPart for property in multipart request model
  /** The number of images to generate. Must be between 1 and 10. */
  n?: HttpPart<OneToTenInt | null>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.
    """)
  response_format?: HttpPart<"url" | "b64_json" | null>;

  // Tool customization: Apply HttpPart for property in multipart request model
  @doc("""
    The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.
    """)
  size?: HttpPart<"256x256" | "512x512" | "1024x1024" | null>;

  // Tool customization: Apply HttpPart for property in multipart request model
  /** A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids). */
  user?: HttpPart<string>;
}

/** The response from the image generation endpoint. */
model ImagesResponse {
  // Tool customization: 'created' and fields ending in '_at' are Unix encoded utcDateTime
  /** The Unix timestamp (in seconds) of when the image was created. */
  @encode("unixTimestamp", int32)
  created: utcDateTime;

  /** The list of generated images. */
  data?: Image[];

  @doc("""
    For `gpt-image-1` only, the token usage information for the image generation.
    """)
  usage?: {
    /** The total number of tokens (images and text) used for the image generation. */
    total_tokens: int32;

    /** The number of tokens (images and text) in the input prompt. */
    input_tokens: int32;

    /** The number of image tokens in the output image. */
    output_tokens: int32;

    /** The input tokens detailed information for the image generation. */
    input_tokens_details: {
      /** The number of text tokens in the input prompt. */
      text_tokens: int32;

      /** The number of image tokens in the input prompt. */
      image_tokens: int32;
    };
  };
}

/** Represents the content or the URL of an image generated by the OpenAI API. */
model Image {
  // Tool customization: base64 input uses an encoded bytes type
  @doc("""
    The base64-encoded JSON of the generated image. Default value for `gpt-image-1`, and only present if `response_format` is set to `b64_json` for `dall-e-2` and `dall-e-3`.
    """)
  @encode("base64", string)
  b64_json?: bytes;

  // Tool customization: url uses the url type
  @doc("""
    When using `dall-e-2` or `dall-e-3`, the URL of the generated image if `response_format` is set to `url` (default value). Unsupported for `gpt-image-1`.
    """)
  url?: url;

  @doc("""
    For `dall-e-3` only, the revised prompt that was used to generate the image.
    """)
  revised_prompt?: string;
}
